#!/usr/bin/env python3
"""
æ™ºèƒ½å®¢æœæœºå™¨äººåç«¯å¯åŠ¨è„šæœ¬
"""

import os
import sys
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        "data/chroma_db",
        "logs"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"âœ“ åˆ›å»ºç›®å½•: {directory}")

def check_ollama_service():
    """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
    try:
        import httpx
        response = httpx.get("http://localhost:11434/api/tags", timeout=5.0)
        if response.status_code == 200:
            print("âœ“ OllamaæœåŠ¡è¿è¡Œæ­£å¸¸")
            return True
        else:
            print("âœ— OllamaæœåŠ¡å“åº”å¼‚å¸¸")
            return False
    except Exception as e:
        print(f"âœ— æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {e}")
        print("è¯·ç¡®ä¿Ollamaå·²å®‰è£…å¹¶è¿è¡Œ: ollama serve")
        return False

def check_models():
    """æ£€æŸ¥å¿…è¦çš„æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
    try:
        import httpx
        response = httpx.get("http://localhost:11434/api/tags", timeout=10.0)
        if response.status_code == 200:
            models = response.json().get("models", [])
            model_names = [model["name"] for model in models]
            
            required_models = [
                "deepseek-r1:latest",
                "modelscope.cn/Qwen/Qwen3-Embedding-8B-GGUF:latest"
            ]
            
            missing_models = []
            for model in required_models:
                if not any(model in name for name in model_names):
                    missing_models.append(model)
            
            if missing_models:
                print("âœ— ç¼ºå°‘ä»¥ä¸‹æ¨¡å‹:")
                for model in missing_models:
                    print(f"  - {model}")
                print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸‹è½½æ¨¡å‹:")
                for model in missing_models:
                    print(f"  ollama pull {model}")
                return False
            else:
                print("âœ“ æ‰€æœ‰å¿…éœ€æ¨¡å‹å·²ä¸‹è½½")
                return True
    except Exception as e:
        print(f"âœ— æ£€æŸ¥æ¨¡å‹å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– å¯åŠ¨æ™ºèƒ½å®¢æœæœºå™¨äººåç«¯æœåŠ¡")
    print("=" * 50)
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    create_directories()
    
    # æ£€æŸ¥OllamaæœåŠ¡
    if not check_ollama_service():
        sys.exit(1)
    
    # æ£€æŸ¥æ¨¡å‹
    if not check_models():
        sys.exit(1)
    
    # å¯åŠ¨FastAPIæœåŠ¡
    print("\nğŸš€ å¯åŠ¨FastAPIæœåŠ¡...")
    try:
        import uvicorn
        uvicorn.run(
            "main:app",
            host="0.0.0.0",
            port=8000,
            reload=True,
            log_level="info"
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢")
    except Exception as e:
        print(f"âœ— å¯åŠ¨æœåŠ¡å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main()) 