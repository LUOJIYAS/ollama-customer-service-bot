# æ™ºèƒ½å®¢æœæœºå™¨äºº

åŸºäº Ollama 0.9.3 + Next.js + FastAPI çš„æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œæ”¯æŒçŸ¥è¯†åº“ç®¡ç†å’Œæµå¼å¯¹è¯ã€‚

## ğŸŒŸ åŠŸèƒ½ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ¤– **æ™ºèƒ½å¯¹è¯**: åŸºäº Ollama çš„æµå¼ AI å¯¹è¯
- ğŸ“š **çŸ¥è¯†åº“ç®¡ç†**: å¯è§†åŒ–çš„çŸ¥è¯†åº“å¢åˆ æ”¹æŸ¥
- ğŸ” **è¯­ä¹‰æœç´¢**: ChromaDB å‘é‡æ•°æ®åº“æ”¯æŒçš„æ™ºèƒ½æ£€ç´¢
- ğŸ“ **æ–‡ä»¶ä¸Šä¼ **: æ”¯æŒ PDFã€Wordã€Excelã€JSON ç­‰æ ¼å¼
- ğŸ“Š **ç»Ÿè®¡åˆ†æ**: çŸ¥è¯†åº“ä½¿ç”¨ç»Ÿè®¡å’Œç›‘æ§

### æŠ€æœ¯æ¶æ„
- **å‰ç«¯**: Next.js 14 + TypeScript + Ant Design UI
- **åç«¯**: Python FastAPI + ChromaDB
- **AIæ¨¡å‹**: 
  - å¯¹è¯æ¨¡å‹: `deepseek-r1:latest`
  - åµŒå…¥æ¨¡å‹: `modelscope.cn/Qwen/Qwen3-Embedding-8B-GGUF:latest`
- **å‘é‡æ•°æ®åº“**: ChromaDB
- **APIæ ‡å‡†**: OpenAIå…¼å®¹APIæ ¼å¼

## ğŸ› ï¸ ç³»ç»Ÿè¦æ±‚

- **Python**: 3.8+
- **Node.js**: 16+
- **Ollama**: 0.9.3
- **æ“ä½œç³»ç»Ÿ**: Windows 10/11
- **å†…å­˜**: å»ºè®® 16GB+ï¼ˆæ¨¡å‹åŠ è½½éœ€è¦ï¼‰

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†é¡¹ç›®
```bash
git clone <repository-url>
cd ollama-customer-service-bot
```

### 2. å®‰è£…Ollamaå¹¶æ‹‰å–æ¨¡å‹
```bash
# å®‰è£…Ollama (å¦‚æœæœªå®‰è£…)
# ä» https://ollama.com/download ä¸‹è½½å¹¶å®‰è£…

# å¯åŠ¨OllamaæœåŠ¡
ollama serve

# æ‹‰å–æ‰€éœ€æ¨¡å‹
ollama pull deepseek-r1:latest
ollama pull modelscope.cn/Qwen/Qwen3-Embedding-8B-GGUF:latest
```

### 3. ç³»ç»Ÿæ£€æŸ¥
```bash
# è¿è¡Œç³»ç»Ÿæ£€æŸ¥è„šæœ¬
system_check.bat
```

### 4. ä¸€é”®å¯åŠ¨
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
start_all.bat
```

## ğŸš€ æ‰‹åŠ¨å¯åŠ¨

### åç«¯å¯åŠ¨
```bash
cd back-end-pages
pip install -r requirements.txt
python main.py
```

### å‰ç«¯å¯åŠ¨
```bash
cd front-end-pages
npm install
npm run dev
```

## ğŸŒ è®¿é—®åœ°å€

- **å‰ç«¯ç•Œé¢**: http://localhost:3000
- **åç«¯API**: http://localhost:8000
- **APIæ–‡æ¡£**: http://localhost:8000/docs
- **å¥åº·æ£€æŸ¥**: http://localhost:8000/health

## ğŸ“ é¡¹ç›®ç»“æ„

```
ollama-customer-service-bot/
â”œâ”€â”€ back-end-pages/              # åç«¯ä»£ç 
â”‚   â”œâ”€â”€ services/               # æœåŠ¡å±‚
â”‚   â”‚   â”œâ”€â”€ ollama_client.py   # Ollama APIå®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ vector_store.py    # ChromaDBå‘é‡å­˜å‚¨
â”‚   â”‚   â””â”€â”€ knowledge_manager.py # çŸ¥è¯†åº“ç®¡ç†
â”‚   â”œâ”€â”€ utils/                 # å·¥å…·ç±»
â”‚   â”œâ”€â”€ main.py               # FastAPIä¸»åº”ç”¨
â”‚   â”œâ”€â”€ config.py             # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ requirements.txt      # Pythonä¾èµ–
â”‚   â””â”€â”€ check_ollama.py       # OllamaæœåŠ¡æ£€æŸ¥
â”œâ”€â”€ front-end-pages/            # å‰ç«¯ä»£ç 
â”‚   â”œâ”€â”€ pages/                # Next.jsé¡µé¢
â”‚   â”œâ”€â”€ components/           # Reactç»„ä»¶
â”‚   â”œâ”€â”€ services/             # APIæœåŠ¡
â”‚   â”œâ”€â”€ styles/               # æ ·å¼æ–‡ä»¶
â”‚   â””â”€â”€ package.json          # Node.jsä¾èµ–
â”œâ”€â”€ start_all.bat             # ä¸€é”®å¯åŠ¨è„šæœ¬
â”œâ”€â”€ system_check.bat          # ç³»ç»Ÿæ£€æŸ¥è„šæœ¬
â”œâ”€â”€ setup_frontend.bat        # å‰ç«¯ç¯å¢ƒè®¾ç½®
â””â”€â”€ README.md                 # é¡¹ç›®æ–‡æ¡£
```

## ğŸ”§ APIæ–‡æ¡£

### èŠå¤©æ¥å£
```http
POST /api/chat
Content-Type: application/json

{
  "message": "ç”¨æˆ·æ¶ˆæ¯",
  "history": [
    {"role": "user", "content": "å†å²æ¶ˆæ¯"},
    {"role": "assistant", "content": "AIå›å¤"}
  ]
}
```

### çŸ¥è¯†åº“ç®¡ç†
```http
# æ·»åŠ çŸ¥è¯†
POST /api/knowledge
{
  "title": "æ ‡é¢˜",
  "content": "å†…å®¹",
  "category": "åˆ†ç±»",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"]
}

# æœç´¢çŸ¥è¯†
POST /api/knowledge/search
{
  "query": "æœç´¢å…³é”®è¯",
  "top_k": 5
}

# è·å–ç»Ÿè®¡
GET /api/knowledge/stats
```

## ğŸ¨ ç•Œé¢å±•ç¤º

- **ç°ä»£åŒ–UI**: åŸºäºAnt Designçš„ä¸“ä¸šç•Œé¢è®¾è®¡
- **å“åº”å¼å¸ƒå±€**: æ”¯æŒPCå’Œç§»åŠ¨ç«¯
- **å®æ—¶å¯¹è¯**: æµå¼å“åº”çš„èŠå¤©ä½“éªŒ
- **çŸ¥è¯†åº“ç®¡ç†**: ç›´è§‚çš„å¯è§†åŒ–ç®¡ç†ç•Œé¢

## âš™ï¸ é…ç½®è¯´æ˜

### Ollamaé…ç½®
```python
# back-end-pages/config.py
OLLAMA_BASE_URL = "http://localhost:11434"
CHAT_MODEL = "deepseek-r1:latest"
EMBEDDING_MODEL = "modelscope.cn/Qwen/Qwen3-Embedding-8B-GGUF:latest"
```

### å‰ç«¯é…ç½®
```javascript
// front-end-pages/next.config.js
module.exports = {
  reactStrictMode: true,
  async rewrites() {
    return [
      {
        source: '/api/:path*',
        destination: 'http://localhost:8000/api/:path*'
      }
    ]
  }
}
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: Ollamaè¿æ¥å¤±è´¥
A: ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ (`ollama serve`)ï¼Œå¹¶æ£€æŸ¥ç«¯å£11434æ˜¯å¦å¯è®¿é—®

### Q: æ¨¡å‹åŠ è½½æ…¢
A: é¦–æ¬¡ä½¿ç”¨æ—¶æ¨¡å‹éœ€è¦åŠ è½½åˆ°å†…å­˜ï¼Œå»ºè®®é¢„çƒ­ï¼š`ollama run deepseek-r1:latest`

### Q: å‰ç«¯ä¾èµ–å®‰è£…å¤±è´¥
A: è¿è¡Œ `setup_frontend.bat` æˆ–æ‰‹åŠ¨æ‰§è¡Œ `npm install --legacy-peer-deps`

### Q: å†…å­˜ä¸è¶³
A: ç¡®ä¿ç³»ç»Ÿæœ‰è¶³å¤Ÿå†…å­˜ï¼ˆå»ºè®®16GB+ï¼‰ï¼Œæˆ–è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹

## ğŸ“ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„çŸ¥è¯†æº
1. åœ¨ `knowledge_manager.py` ä¸­æ·»åŠ å¤„ç†é€»è¾‘
2. æ›´æ–°å‰ç«¯ä¸Šä¼ ç»„ä»¶æ”¯æŒæ–°æ ¼å¼
3. æµ‹è¯•å‘é‡åŒ–å’Œæ£€ç´¢åŠŸèƒ½

### è‡ªå®šä¹‰æ¨¡å‹
1. ä¿®æ”¹ `config.py` ä¸­çš„æ¨¡å‹é…ç½®
2. ç¡®ä¿æ¨¡å‹å·²åœ¨Ollamaä¸­å®‰è£…
3. è¿è¡Œç³»ç»Ÿæ£€æŸ¥éªŒè¯

### ç•Œé¢å®šåˆ¶
1. ä¿®æ”¹ `styles/globals.css` è°ƒæ•´å…¨å±€æ ·å¼
2. åœ¨ç»„ä»¶ä¸­ä½¿ç”¨Ant Designä¸»é¢˜å®šåˆ¶
3. å‚è€ƒ `style.jpg` ä¿æŒç•Œé¢ä¸€è‡´æ€§

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚é‡é—®é¢˜ï¼Œè¯·ï¼š
1. é¦–å…ˆè¿è¡Œ `system_check.bat` æ£€æŸ¥ç¯å¢ƒ
2. æŸ¥çœ‹åç«¯æ—¥å¿—: `back-end-pages/logs/`
3. æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€: `ollama list`

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚è¯¦è§LICENSEæ–‡ä»¶ã€‚

---

ğŸš€ **ç«‹å³å¼€å§‹**: è¿è¡Œ `system_check.bat` ç„¶å `start_all.bat` 